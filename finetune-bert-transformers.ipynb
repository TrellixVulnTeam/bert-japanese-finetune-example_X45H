{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ldcc-20140209.tar.gz already exists. download stopped\n",
      "./lldc already exists. extract stopped\n"
     ]
    }
   ],
   "source": [
    "from livedoor import LivedoorNewsCorpus\n",
    "\n",
    "corpus = LivedoorNewsCorpus(extract_dir='./lldc')\n",
    "corpus.download_and_extract()\n",
    "categories = corpus.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_text, all_label = corpus.get_text_and_labels()\n",
    "df = pd.DataFrame({'text': all_text, 'label': all_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_sentence_to_ids(_sentences, tokenizer):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # 1文づつ処理\n",
    "    for sent in _sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      \n",
    "                            add_special_tokens = True,\n",
    "                            max_length = 37,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                       )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factory import get_model, get_optimizers, get_tokenizer, get_dataloader\n",
    "\n",
    "model = get_model(num_labels=len(categories))\n",
    "optimizer = get_optimizers(model)\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sentences = df.text.values\n",
    "_labels = df.label.astype('category').cat.codes\n",
    "# 文字列のラベルを数値に変換するところはpandasのcategory型を使ったが、pandas頼らなくても良い\n",
    "\n",
    "id_and_masks = convert_sentence_to_ids(_sentences, tokenizer)\n",
    "labels = torch.tensor(_labels, dtype=torch.int64)\n",
    "ds_source = id_and_masks + (labels,)\n",
    "\n",
    "train_dl, valid_dl = get_dataloader(ds_source, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Training took: 0:00:28\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Training took: 0:00:28\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Training took: 0:00:28\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Training took: 0:00:28\n",
      "\n",
      "Running Validation...\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:58 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "from fit import fit\n",
    "stats = fit(model, train_dl, valid_dl, optimizer, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'Training Loss': 1.0470423494967132,\n",
       "  'Valid. Loss': 0.46964893117547035,\n",
       "  'Valid. Accur.': 0.85546875,\n",
       "  'Training Time': '0:00:28',\n",
       "  'Validation Time': '0:00:01'},\n",
       " {'epoch': 2,\n",
       "  'Training Loss': 0.3440260239876807,\n",
       "  'Valid. Loss': 0.38929920829832554,\n",
       "  'Valid. Accur.': 0.8763020833333334,\n",
       "  'Training Time': '0:00:28',\n",
       "  'Validation Time': '0:00:01'},\n",
       " {'epoch': 3,\n",
       "  'Training Loss': 0.17243757750838995,\n",
       "  'Valid. Loss': 0.3836299367249012,\n",
       "  'Valid. Accur.': 0.8919270833333334,\n",
       "  'Training Time': '0:00:28',\n",
       "  'Validation Time': '0:00:01'},\n",
       " {'epoch': 4,\n",
       "  'Training Loss': 0.08538434787008625,\n",
       "  'Valid. Loss': 0.4766979559014241,\n",
       "  'Valid. Accur.': 0.8815104166666666,\n",
       "  'Training Time': '0:00:28',\n",
       "  'Validation Time': '0:00:01'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
